<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="color-scheme" content="light" />
    <title>Andrew Bai</title>
    <style>
      body {
        font-size: 18px;
        max-width: 960px;
        margin: 0 auto;
        padding: 10px;
      }
      h1, h2, h3, h4, h5, h6 {
        font-weight: unset;
      }
      nav {
        text-align: right;
      }
      nav a {
        display: inline-block;
        margin: 0 0.2em;
        color: unset;
      }
    </style>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-GZQJJ9R5QZ"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-GZQJJ9R5QZ');
    </script>
  </head>
  <body>
    <main>
      <h1>Andrew (Ching-Yuan) Bai</h1>
      <p>Hello! Welcome to my personal website.</p>
      <p>I am a 3rd year PhD student in Computer Science at UCLA, where I work with <a href="http://web.cs.ucla.edu/~chohsieh/">Cho-Jui Hsieh</a>.
      I am interested in understanding why machine learning methods work and debunking machine learning myths. 
      Specifically I aim to make black-box machine learning models more interpretable to allow better control.</p>
      <p>Currently I am developing simple and easy-to-adopt <b>sample selection schemes</b> for prioritizing data samples during training (sample-based interpretability).
      I also worked on developing <b>practical interpretation methods</b> for black-box models, allowing humans to better understand and trust machine learning models in real life (concept-based interpretability).</p>

      <p>Previously, I was an undergraduate student in Computer Science at National Taiwan University.
      I worked with <a href="https://www.csie.ntu.edu.tw/~htlin/">Hsuan-Tien Lin</a> on <b>generative modeling</b> and <b>time series forecasting</b>.
      We held the <a href="https://www.kaggle.com/c/generative-dog-images">first-ever generative modeling competition</a> in collaboration with Kaggle.
      I also worked with <a href="https://www.csie.ntu.edu.tw/~cwlin/">Chung-Wei Lin</a> on <b>system verification</b> and <b>falsification</b>.</p>

      <p>Email: andrewbai [AT] cs.ucla.edu</p>
      <p>Links: [<a href="./files/cv.pdf">CV</a>] [<a href="https://github.com/jybai">Github</a>] [<a href="https://www.linkedin.com/in/andrew-bai-a455b815b/">Linkedin</a>]</p>

      <!--<h2>Preprint</h2>-->

      <h2>Publications</h2>
      <h3>2024</h3>
      <ul>
        <li> <b>Andrew Bai</b>, Chih-Kuan Yeh, Cho-Jui Hsieh, Ankur Taly. Which Pretrain Samples to Review when Fine-tuning Pretrained Models? Under submission review.
        </li>
        <li> Tong Xie*, Haoyu Li*, <b>Andrew Bai</b>, Cho-Jui Hsieh. Data Attribution for Diffusion Models: Timestep-induced Bias in Influence Estimation. Under submission review.
          <br>
          [<a href="./files/bib/xie2024data.bib">bib</a> | 
           <a href="https://arxiv.org/abs/2401.09031">arxiv</a>]
        </li>
      </ul>
      <h3>2023</h3>
      <ul>
        <li> <b>Andrew Bai</b>, Chih-Kuan Yeh, Pradeep Ravikumar, Neil Y. C. Lin, Cho-Jui Hsieh. Concept Gradient: Concept-based Interpretation Without Linear Assumption. In Proceedings of the 11th International Conference on Learning Representations (ICLR), May 2023.
          <br>
          [<a href="./files/bib/ab2022cg.bib">bib</a> | 
           <a href="https://arxiv.org/abs/2208.14966">arxiv</a> |
           <a href="https://github.com/jybai/concept-gradients">code</a>]
        </li>
      </ul>
      <h3>2022</h3>
      <ul>
        <li> <b>Andrew Bai</b>, Cho-Jui Hsieh, Wendy Chih-wen Kan, Hsuan-Tien Lin. Reducing Training Sample Memorization in GANs by Training with Memorization Rejection. Arxiv preprint.
          <br>
          [<a href="./files/bib/bai2022reducing.bib">bib</a> | 
           <a href="https://arxiv.org/abs/2210.12231">arxiv</a> |
           <a href="https://github.com/jybai/MRGAN">code</a>]
        </li>
      </ul>
      <h3>2021</h3>
      <ul>
        <li> <b>Ching-Yuan Bai</b>, Hsuan-Tien Lin, Colin Raffel, and Wendy Chih-wen Kan. On training sample memorization: Lessons from benchmarking generative modeling with a large-scale competition. In Proceedings of the 27th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), August 2021.
          <br>
          [<a href="./files/bib/cb2021on.bib">bib</a> | 
           <a href="https://www.kaggle.com/andrewcybai/generative-dog-images">data</a> |
           <a href="https://arxiv.org/abs/2106.03062">arxiv</a> |
           <a href="https://github.com/jybai/generative-memorization-benchmark">code</a> ]
        </li>
      </ul>
      <h3>2020</h3>
      <ul>
        <li>Shih-Lun Wu*, <b>Ching-Yuan Bai</b>*, Kai-Chieh Chang, Yi-Ting Hsieh, Chao Huang, Chung-Wei Lin, Eunsuk Kang, and Qi Zhu. Efficient system verification with multiple weakly-hard constraints for runtime monitoring. In Proceedings of the International Conference on Runtime Verification (RV), October 2020.
          <br>
          [<a href="./files/bib/sw2020efficient.bib">bib</a> | 
           <a href="./files/paper/sw2020efficient.pdf">pdf</a>  ]
        </li>
        <li><b>Ching-Yuan Bai</b>, Buo-Fu Chen, and Hsuan-Tien Lin. Benchmarking tropical cyclone rapid intensification with satellite images and attention-based deep models. In Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML/PKDD), September 2020. 
          <br>
          [<a href="./files/bib/cb2020benchmarking.bib">bib</a> | 
           <a href="https://www.csie.ntu.edu.tw/~htlin/program/TCRISI/">data</a> |
           <a href="https://arxiv.org/abs/1909.11616">arxiv</a> |
           <a href="https://github.com/jybai/TCRI-Benchmark">code</a> ]
        </li>
      </ul>
    </main>
  </body>
</html>
